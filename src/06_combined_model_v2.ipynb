{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-bashari-m/vehicle-color-recognition/blob/main/src/06_combined_model_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HytB7-lTs7g5",
        "outputId": "5e0034a6-bfc4-415b-cd07-13d48c860c7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at ./drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('./drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dQvl_Em4s8Oi",
        "outputId": "09c3bf72-a1ba-42a9-c66f-fb875f6e552f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 25.9 MB 1.5 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "!pip install -q tensorflow-io\n",
        "import tensorflow_io as tfio\n",
        "\n",
        "from utils import get_train_val_ds, get_class_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "S5qkZw4Ns8Z7"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (256, 256)\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "N_CLASSES = 16\n",
        "HUB_URL = 'https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_b3/feature_vector/2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "J8g_1jhQtDFq"
      },
      "outputs": [],
      "source": [
        "dataset_dir = os.path.join('drive', 'MyDrive', 'cars')\n",
        "train_dir = os.path.join(dataset_dir, 'train')\n",
        "val_dir = os.path.join(dataset_dir, 'val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZDdC4GywtEQh",
        "outputId": "98c3fdc0-f913-4b30-8e45-453acdb2722d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 16580 files belonging to 16 classes.\n",
            "Found 3495 files belonging to 16 classes.\n"
          ]
        }
      ],
      "source": [
        "train_ds, val_ds = get_train_val_ds(train_dir, val_dir, batch_size=BATCH_SIZE, img_size=IMG_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VfXJuXaItHeC"
      },
      "outputs": [],
      "source": [
        "classes, class_weight = get_class_weight()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YUizq5ZwtHqM"
      },
      "outputs": [],
      "source": [
        "train_ds = (\n",
        "    train_ds.\n",
        "    map(lambda img, lbl: (img/255., lbl), num_parallel_calls=AUTOTUNE).\n",
        "    prefetch(AUTOTUNE))\n",
        "\n",
        "val_ds = (\n",
        "    val_ds.\n",
        "    map(lambda img, lbl: (img/255., lbl), num_parallel_calls=AUTOTUNE).\n",
        "    prefetch(AUTOTUNE))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rgb_input = keras.Input(shape=IMG_SIZE+(3,))\n",
        "rgb_hub_module = hub.KerasLayer(HUB_URL,  trainable=True)\n",
        "hsv_hub_module = hub.KerasLayer(HUB_URL,  trainable=True)\n",
        "xyz_hub_module = hub.KerasLayer(HUB_URL,  trainable=True)\n",
        "\n",
        "rgb_features = rgb_hub_module(rgb_input)\n",
        "\n",
        "xyz_input = tfio.experimental.color.rgb_to_xyz(rgb_input)\n",
        "xyz_features = xyz_hub_module(xyz_input)\n",
        "\n",
        "hsv_input = tf.image.rgb_to_hsv(rgb_input)\n",
        "hsv_features = hsv_hub_module(hsv_input)\n",
        "\n",
        "features = keras.layers.Concatenate()([rgb_features, xyz_features, hsv_features])\n",
        "\n",
        "output = keras.layers.Dense(N_CLASSES, activation='softmax')(features)\n",
        "\n",
        "model = keras.models.Model(inputs=[rgb_input], outputs=[output])"
      ],
      "metadata": {
        "id": "yY2InyDe18Px"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model._name = 'combined-model'"
      ],
      "metadata": {
        "id": "x9Cf6BCzCHdO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = [\n",
        "            keras.metrics.AUC(name='auc', curve='PR', num_thresholds=100),\n",
        "            'accuracy'\n",
        "          ]\n",
        "\n",
        "loss_fn = keras.losses.CategoricalCrossentropy()\n",
        "lr_schedule =tf.keras.optimizers.schedules.ExponentialDecay(1e-3, 500, .9)\n",
        "\n",
        "model.compile(loss=loss_fn,\n",
        "            optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "            metrics=metrics)"
      ],
      "metadata": {
        "id": "ZtVjR1lMAlyA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "                                              monitor='val_auc', \n",
        "                                              verbose=1,\n",
        "                                              patience=5,\n",
        "                                              mode='max')\n",
        "\n",
        "check_point_path = os.path.join('./logs/checkpoints', model._name+\".h5\")\n",
        "check_point = keras.callbacks.ModelCheckpoint(\n",
        "                                            filepath=check_point_path,\n",
        "                                            monitor='val_auc',\n",
        "                                            save_best_only=True,\n",
        "                                            mode='max')\n",
        "        \n",
        "callbacks = [early_stopping, check_point]"
      ],
      "metadata": {
        "id": "auoSXmr3A4i3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "81hWi4y1utc0",
        "outputId": "e459285c-0db0-4ec8-c28b-faa32e501537"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-fcc3ea21444e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     class_weight=class_weight)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  failed to allocate memory\n\t [[{{node Sigmoid}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[assert_less_equal/Assert/AssertGuard/pivot_f/_10135/_213]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  failed to allocate memory\n\t [[{{node Sigmoid}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_320380]"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_ds,\n",
        "                    callbacks=callbacks,\n",
        "                    epochs=15,\n",
        "                    validation_data=val_ds,\n",
        "                    class_weight=class_weight)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp ./logs/checkpoints/combined-model-10.h5 ./drive/MyDrive/checkpoints/combined-model-10.2.h5\n",
        "!cp ./logs/checkpoints/combined-model-15.h5 ./drive/MyDrive/checkpoints/combined-model-15.2.h5\n",
        "!cp ./logs/checkpoints/combined-model-20.h5 ./drive/MyDrive/checkpoints/combined-model-20.2.h5"
      ],
      "metadata": {
        "id": "uu5oTNQZOS7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_ds,\n",
        "                    callbacks=callbacks,\n",
        "                    epochs=30,\n",
        "                    initial_epoch=20,\n",
        "                    class_weight=class_weight)"
      ],
      "metadata": {
        "id": "fWRIQIL6STD6",
        "outputId": "6d26cdbe-de7d-46a5-d44e-ad8753b48559",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/30\n",
            "533/533 [==============================] - 3123s 6s/step - loss: 5.6207 - auc: 0.9592 - accuracy: 0.9698\n",
            "Epoch 22/30\n",
            "533/533 [==============================] - 449s 839ms/step - loss: 4.0567 - auc: 0.9673 - accuracy: 0.9739\n",
            "Epoch 23/30\n",
            "533/533 [==============================] - 448s 839ms/step - loss: 3.2036 - auc: 0.9746 - accuracy: 0.9780\n",
            "Epoch 24/30\n",
            "533/533 [==============================] - 448s 838ms/step - loss: 3.1084 - auc: 0.9736 - accuracy: 0.9782\n",
            "Epoch 25/30\n",
            "533/533 [==============================] - 448s 839ms/step - loss: 2.2643 - auc: 0.9796 - accuracy: 0.9810\n",
            "Epoch 26/30\n",
            "533/533 [==============================] - 448s 839ms/step - loss: 2.1500 - auc: 0.9825 - accuracy: 0.9830\n",
            "Epoch 27/30\n",
            "533/533 [==============================] - 449s 840ms/step - loss: 1.4366 - auc: 0.9879 - accuracy: 0.9886\n",
            "Epoch 28/30\n",
            "533/533 [==============================] - 448s 838ms/step - loss: 1.4828 - auc: 0.9863 - accuracy: 0.9868\n",
            "Epoch 29/30\n",
            "533/533 [==============================] - 449s 839ms/step - loss: 1.3289 - auc: 0.9888 - accuracy: 0.9885\n",
            "Epoch 30/30\n",
            "533/533 [==============================] - 448s 839ms/step - loss: 0.9875 - auc: 0.9913 - accuracy: 0.9908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp ./logs/checkpoints/combined-model-25.h5 ./drive/MyDrive/checkpoints/combined-model-25.2.h5\n",
        "!cp ./logs/checkpoints/combined-model-30.h5 ./drive/MyDrive/checkpoints/combined-model-30.2.h5"
      ],
      "metadata": {
        "id": "PFn12cjjckKJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "xyz_model.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}